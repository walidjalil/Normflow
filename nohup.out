Initializing dataset...
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
3200
3300
3400
3500
3600
3700
3800
3900
4000
4100
4200
4300
4400
4500
4600
4700
4800
4900
5000
5100
5200
5300
5400
5500
5600
5700
5800
5900
6000
6100
6200
6300
6400
6500
6600
6700
6800
6900
7000
7100
7200
7300
7400
7500
7600
7700
7800
7900
8000
8100
8200
8300
8400
8500
8600
8700
8800
8900
9000
9100
9200
9300
9400
9500
9600
9700
9800
9900
10000
10100
10200
10300
10400
10500
10600
10700
10800
10900
11000
11100
11200
11300
11400
11500
11600
11700
11800
11900
12000
12100
12200
12300
12400
12500
12600
12700
12800
12900
13000
13100
13200
13300
13400
13500
13600
13700
13800
13900
14000
14100
14200
14300
14400
14500
14600
14700
14800
14900
15000
15100
15200
15300
15400
15500
15600
15700
15800
15900
16000
16100
16200
16300
16400
16500
16600
16700
16800
16900
17000
17100
17200
17300
17400
17500
17600
17700
17800
17900
18000
18100
18200
18300
18400
18500
18600
18700
18800
18900
19000
19100
19200
19300
19400
19500
19600
19700
19800
19900
20000
20100
20200
20300
20400
20500
20600
20700
20800
20900
21000
21100
21200
21300
21400
21500
21600
21700
21800
21900
22000
22100
22200
22300
22400
22500
22600
22700
22800
22900
23000
23100
23200
23300
23400
23500
23600
23700
23800
23900
24000
24100
24200
24300
24400
24500
24600
24700
24800
24900
25000
25100
25200
25300
25400
25500
25600
25700
25800
25900
26000
26100
26200
26300
26400
26500
26600
26700
26800
26900
27000
27100
27200
27300
27400
27500
27600
27700
27800
27900
28000
28100
28200
28300
28400
28500
28600
28700
28800
28900
29000
29100
29200
29300
29400
29500
29600
29700
29800
29900
30000
30100
30200
30300
30400
30500
30600
30700
30800
30900
31000
31100
31200
31300
31400
31500
31600
31700
31800
31900
32000
32100
32200
32300
32400
32500
32600
32700
32800
32900
33000
33100
33200
33300
33400
33500
33600
33700
33800
33900
34000
34100
34200
34300
34400
34500
34600
34700
34800
34900
35000
35100
35200
35300
35400
35500
35600
35700
35800
35900
36000
36100
36200
36300
36400
36500
36600
36700
36800
36900
37000
37100
37200
37300
37400
37500
37600
37700
37800
37900
38000
38100
38200
38300
38400
38500
38600
38700
38800
38900
39000
39100
39200
39300
39400
39500
39600
39700
39800
39900
40000
40100
40200
40300
40400
40500
40600
40700
40800
40900
41000
41100
41200
41300
41400
41500
41600
41700
41800
41900
42000
42100
42200
42300
42400
42500
42600
42700
42800
42900
43000
43100
43200
43300
43400
43500
43600
43700
43800
43900
44000
44100
44200
44300
44400
44500
44600
44700
44800
44900
45000
45100
45200
45300
45400
45500
45600
45700
45800
45900
46000
46100
46200
46300
46400
46500
46600
46700
46800
46900
47000
47100
47200
47300
47400
47500
47600
47700
47800
47900
48000
48100
48200
48300
48400
48500
48600
48700
48800
48900
49000
49100
49200
49300
49400
49500
49600
49700
49800
49900
50000
50100
50200
50300
50400
50500
50600
50700
50800
50900
51000
51100
51200
51300
51400
51500
51600
51700
51800
51900
52000
52100
52200
52300
52400
52500
52600
52700
52800
52900
52976
Dataset initialized
 
Beginning training now:
 
train loss:  9.24783111347752
val loss:  1.9975166416937304
-------------------------------------------------
train loss:  1.8725241933065662
val loss:  1.801950817146609
-------------------------------------------------
train loss:  1.7626252540653495
val loss:  1.727071903405651
-------------------------------------------------
train loss:  1.7076997784089567
val loss:  1.6839054092284171
-------------------------------------------------
train loss:  1.6744537775750519
val loss:  1.6560583816420646
-------------------------------------------------
train loss:  1.6496835955515357
val loss:  1.6372691575557954
-------------------------------------------------
train loss:  1.6325646559171283
val loss:  1.6231726254186323
-------------------------------------------------
train loss:  1.618262072036819
val loss:  1.613542510617164
-------------------------------------------------
train loss:  1.6075000544191254
val loss:  1.602304693191282
-------------------------------------------------
train loss:  1.5977279787212821
val loss:  1.592537603070659
-------------------------------------------------
train loss:  1.5898279989427049
val loss:  1.5874561446328317
-------------------------------------------------
train loss:  1.5826148493361167
val loss:  1.581388509081256
-------------------------------------------------
train loss:  1.5760341723307776
val loss:  1.5740841473302534
-------------------------------------------------
train loss:  1.570193970525587
val loss:  1.5658135087259355
-------------------------------------------------
train loss:  1.565993452479117
val loss:  1.563546819071616
-------------------------------------------------
train loss:  1.5613495297994926
val loss:  1.5593338147286446
-------------------------------------------------
train loss:  1.5580553150448317
val loss:  1.555028320320191
-------------------------------------------------
train loss:  1.5541430050414453
val loss:  1.5534297958497079
-------------------------------------------------
train loss:  1.5512316779764754
val loss:  1.5499058154321486
-------------------------------------------------
train loss:  1.5474351480030912
val loss:  1.5484886602047951
-------------------------------------------------
train loss:  1.5452783509643793
val loss:  1.5441626579530778
-------------------------------------------------
train loss:  1.5416163630031081
val loss:  1.543560004042041
-------------------------------------------------
train loss:  1.5386801815643418
val loss:  1.539310045780674
-------------------------------------------------
train loss:  1.5368014328171145
val loss:  1.5381792976010231
-------------------------------------------------
train loss:  1.5344505481326562
val loss:  1.5347531947397417
-------------------------------------------------
train loss:  1.532264518364734
val loss:  1.5321180282100555
-------------------------------------------------
train loss:  1.5297599863022524
val loss:  1.5304183585028495
-------------------------------------------------
train loss:  1.527849605208949
val loss:  1.5294330312359719
-------------------------------------------------
train loss:  1.5264749815250358
val loss:  1.5293683851918867
-------------------------------------------------
train loss:  1.5249115886593272
val loss:  1.5250462514738883
-------------------------------------------------
train loss:  1.5229244313572412
val loss:  1.5236867493198765
-------------------------------------------------
train loss:  1.5215646220135315
val loss:  1.5259904630722538
-------------------------------------------------
train loss:  1.520047612414082
val loss:  1.5199103345794063
-------------------------------------------------
train loss:  1.5188146693947304
val loss:  1.5216279116369062
-------------------------------------------------
train loss:  1.5167056710418223
val loss:  1.5195367711205636
-------------------------------------------------
train loss:  1.5159211525028495
val loss:  1.519656882170708
-------------------------------------------------
train loss:  1.5145608029019613
val loss:  1.5158340594460886
-------------------------------------------------
train loss:  1.5126989903524624
val loss:  1.516104499178548
-------------------------------------------------
train loss:  1.5115416545108236
val loss:  1.5156053227763022
-------------------------------------------------
train loss:  1.5097604789910242
val loss:  1.5125868656942922
-------------------------------------------------
train loss:  1.5093035238396222
val loss:  1.5110080761294211
-------------------------------------------------
train loss:  1.5080914180275387
val loss:  1.508403754042041
-------------------------------------------------
train loss:  1.5070229519481848
val loss:  1.5093355592220061
-------------------------------------------------
train loss:  1.5056630768104433
val loss:  1.5091552215237771
-------------------------------------------------
train loss:  1.5048519359374284
val loss:  1.5071832095423052
-------------------------------------------------
train loss:  1.504304591317265
val loss:  1.5084251655686287
-------------------------------------------------
train loss:  1.5031325488137994
val loss:  1.5059656289315992
-------------------------------------------------
train loss:  1.5028753441733282
val loss:  1.5036692398209726
-------------------------------------------------
train loss:  1.5012685282640743
val loss:  1.5057052671909332
-------------------------------------------------
train loss:  1.5007114505360848
val loss:  1.503514555192763
-------------------------------------------------
train loss:  1.5000372265345003
val loss:  1.5022274553775787
-------------------------------------------------
train loss:  1.4994091361888273
val loss:  1.5041521979916481
-------------------------------------------------
train loss:  1.4981348351767527
val loss:  1.5026712907898812
-------------------------------------------------
train loss:  1.4978389551765041
val loss:  1.5006772289353032
-------------------------------------------------
train loss:  1.4971543776022422
val loss:  1.5004588538600552
-------------------------------------------------
train loss:  1.4961518134026235
val loss:  1.501695474309306
-------------------------------------------------
train loss:  1.4958392932777893
val loss:  1.4995583776504762
-------------------------------------------------
train loss:  1.4951236487113226
val loss:  1.50069472385991
-------------------------------------------------
train loss:  1.4941971290162412
val loss:  1.497967791172766
-------------------------------------------------
train loss:  1.4932555577493833
val loss:  1.4978327299318006
-------------------------------------------------
train loss:  1.4932189447272723
val loss:  1.4989824698817344
-------------------------------------------------
train loss:  1.4924335244030904
val loss:  1.4965434660834651
-------------------------------------------------
train loss:  1.4916364310645787
val loss:  1.4965540920534441
-------------------------------------------------
train loss:  1.4908791907650987
val loss:  1.4953587891594056
-------------------------------------------------
train loss:  1.4905288002399428
val loss:  1.495589034211251
-------------------------------------------------
train loss:  1.490282411595666
val loss:  1.4955952417465948
-------------------------------------------------
train loss:  1.4895480679583923
val loss:  1.4956877058552158
-------------------------------------------------
train loss:  1.4888687752727763
val loss:  1.4952996469313098
-------------------------------------------------
train loss:  1.4880814864320062
val loss:  1.4952351374010886
-------------------------------------------------
train loss:  1.4872041498105522
val loss:  1.4920487798029376
-------------------------------------------------
train loss:  1.4870556742164862
val loss:  1.4923059373132643
-------------------------------------------------
